{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ5TbPkd-Agn",
        "outputId": "23ca7cd6-d188-4deb-d8c3-97ba1188141a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UniNet'...\n",
            "remote: Enumerating objects: 386, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 386 (delta 112), reused 66 (delta 66), pack-reused 255 (from 2)\u001b[K\n",
            "Receiving objects: 100% (386/386), 6.63 MiB | 12.79 MiB/s, done.\n",
            "Resolving deltas: 100% (186/186), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pangdatangtt/UniNet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XEH-nTmGCIyT"
      },
      "outputs": [],
      "source": [
        "# √ñnce varsa eski linki sil (opsiyonel)\n",
        "!rm -rf /content/UniNet/data\n",
        "\n",
        "# Yeni baƒülantƒ±yƒ± olu≈ütur\n",
        "!ln -s \"/content/drive/MyDrive/Wood_Dataset\" \"/content/UniNet/data\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZpiLAP5-D-s",
        "outputId": "15f8aabc-d989-4105-9988-f9f127364449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on MVTec AD dataset (separate-class)\n",
            "class:wood, domain:industrial, setting:oc, dataset:MVTec AD, epochs:100, batch_size:8, image_size:256, center_crop:256, lr_s:0.005, lr_t:1e-06, T:2, weighted_decision_mechanism:True, default:0.3, alpha:0.01, beta:3e-05, train_and_test_all:True, is_saved:True, save_dir:./results, load_ckpts:False, \n",
            "cuda\n",
            "epoch [1/100], loss:20.4108\n",
            "epoch [2/100], loss:19.7393\n",
            "epoch [3/100], loss:19.5118\n",
            "epoch [4/100], loss:19.3994\n",
            "epoch [5/100], loss:19.3333\n",
            "epoch [6/100], loss:19.2677\n",
            "epoch [7/100], loss:19.2251\n",
            "epoch [8/100], loss:19.1838\n",
            "epoch [9/100], loss:19.1584\n",
            "epoch [10/100], loss:19.1295\n",
            "üïí FPS: 12.84\n",
            "‚úÖ gt_mask max: True, anomaly_map max: 3.7661192417144775\n",
            "üîç Best threshold (F1-max): 2.7200\n",
            "üìä Confusion Matrix (Image-Level):\n",
            " [[ 1 69]\n",
            " [ 1 70]]\n",
            "‚úÖ F1 Score: 0.667 | Accuracy: 0.504\n",
            "üß© pred_masks unique values: [0 1]\n",
            "üìè Mean IoU (Defect Images Only): 0.0450\n",
            "Sample Auroc: 62.0, Pixel Auroc: 79.4, Pixel Aupro: 14.9\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_ROC.pth\n",
            "saved\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_PRO.pth\n",
            "MAX I_ROC: 62.0, MAX P_ROC: 79.4, MAX P_PRO: 14.9\n",
            "epoch [11/100], loss:19.1004\n",
            "epoch [12/100], loss:19.0820\n",
            "epoch [13/100], loss:19.0561\n",
            "epoch [14/100], loss:19.0407\n",
            "epoch [15/100], loss:19.0231\n",
            "epoch [16/100], loss:19.0333\n",
            "epoch [17/100], loss:19.0016\n",
            "epoch [18/100], loss:18.9965\n",
            "epoch [19/100], loss:18.9699\n",
            "epoch [20/100], loss:18.9598\n",
            "üïí FPS: 12.85\n",
            "‚úÖ gt_mask max: True, anomaly_map max: 3.1244444847106934\n",
            "üîç Best threshold (F1-max): 2.2689\n",
            "üìä Confusion Matrix (Image-Level):\n",
            " [[58 12]\n",
            " [ 5 66]]\n",
            "‚úÖ F1 Score: 0.886 | Accuracy: 0.879\n",
            "üß© pred_masks unique values: [0 1]\n",
            "üìè Mean IoU (Defect Images Only): 0.2474\n",
            "Sample Auroc: 93.8, Pixel Auroc: 95.7, Pixel Aupro: 48.9\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_ROC.pth\n",
            "saved\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_PRO.pth\n",
            "MAX I_ROC: 93.8, MAX P_ROC: 95.7, MAX P_PRO: 48.9\n",
            "epoch [21/100], loss:18.9523\n",
            "epoch [22/100], loss:18.9440\n",
            "epoch [23/100], loss:18.9383\n",
            "epoch [24/100], loss:18.9227\n",
            "epoch [25/100], loss:18.9107\n",
            "epoch [26/100], loss:18.8981\n",
            "epoch [27/100], loss:18.8958\n",
            "epoch [28/100], loss:18.8863\n",
            "epoch [29/100], loss:18.8887\n",
            "epoch [30/100], loss:18.8654\n",
            "üïí FPS: 12.83\n",
            "‚úÖ gt_mask max: True, anomaly_map max: 3.1237125396728516\n",
            "üîç Best threshold (F1-max): 2.2115\n",
            "üìä Confusion Matrix (Image-Level):\n",
            " [[60 10]\n",
            " [ 5 66]]\n",
            "‚úÖ F1 Score: 0.898 | Accuracy: 0.894\n",
            "üß© pred_masks unique values: [0 1]\n",
            "üìè Mean IoU (Defect Images Only): 0.2673\n",
            "Sample Auroc: 94.7, Pixel Auroc: 96.3, Pixel Aupro: 49.6\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_ROC.pth\n",
            "saved\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_PRO.pth\n",
            "MAX I_ROC: 94.7, MAX P_ROC: 96.3, MAX P_PRO: 49.6\n",
            "epoch [31/100], loss:18.8596\n",
            "epoch [32/100], loss:18.8527\n",
            "epoch [33/100], loss:18.8466\n",
            "epoch [34/100], loss:18.8494\n",
            "epoch [35/100], loss:18.8463\n",
            "epoch [36/100], loss:18.8296\n",
            "epoch [37/100], loss:18.8292\n",
            "epoch [38/100], loss:18.8200\n",
            "epoch [39/100], loss:18.8139\n",
            "epoch [40/100], loss:18.8060\n",
            "üïí FPS: 12.80\n",
            "‚úÖ gt_mask max: True, anomaly_map max: 3.0961201190948486\n",
            "üîç Best threshold (F1-max): 2.2307\n",
            "üìä Confusion Matrix (Image-Level):\n",
            " [[65  5]\n",
            " [ 9 62]]\n",
            "‚úÖ F1 Score: 0.899 | Accuracy: 0.901\n",
            "üß© pred_masks unique values: [0 1]\n",
            "üìè Mean IoU (Defect Images Only): 0.2608\n",
            "Sample Auroc: 95.5, Pixel Auroc: 96.5, Pixel Aupro: 49.8\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_ROC.pth\n",
            "saved\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_PRO.pth\n",
            "MAX I_ROC: 95.5, MAX P_ROC: 96.5, MAX P_PRO: 49.8\n",
            "epoch [41/100], loss:18.8078\n",
            "epoch [42/100], loss:18.7933\n",
            "epoch [43/100], loss:18.7848\n",
            "epoch [44/100], loss:18.7824\n",
            "epoch [45/100], loss:18.7779\n",
            "epoch [46/100], loss:18.7711\n",
            "epoch [47/100], loss:18.7699\n",
            "epoch [48/100], loss:18.7522\n",
            "epoch [49/100], loss:18.7623\n",
            "epoch [50/100], loss:18.7469\n",
            "üïí FPS: 12.85\n",
            "‚úÖ gt_mask max: True, anomaly_map max: 3.0279078483581543\n",
            "üîç Best threshold (F1-max): 2.1389\n",
            "üìä Confusion Matrix (Image-Level):\n",
            " [[59 11]\n",
            " [ 5 66]]\n",
            "‚úÖ F1 Score: 0.892 | Accuracy: 0.887\n",
            "üß© pred_masks unique values: [0 1]\n",
            "üìè Mean IoU (Defect Images Only): 0.2845\n",
            "Sample Auroc: 94.8, Pixel Auroc: 96.7, Pixel Aupro: 52.4\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_ROC.pth\n",
            "saved\n",
            "modules have been saved to ./ckpts/MVTec AD/wood/BEST_P_PRO.pth\n",
            "MAX I_ROC: 95.5, MAX P_ROC: 96.7, MAX P_PRO: 52.4\n",
            "epoch [51/100], loss:18.7407\n",
            "epoch [52/100], loss:18.7389\n",
            "epoch [53/100], loss:18.7307\n",
            "epoch [54/100], loss:18.7200\n",
            "epoch [55/100], loss:18.7168\n",
            "epoch [56/100], loss:18.7143\n",
            "epoch [57/100], loss:18.7154\n",
            "epoch [58/100], loss:18.7055\n",
            "epoch [59/100], loss:18.7009\n",
            "epoch [60/100], loss:18.6956\n",
            "üïí FPS: 12.90\n",
            "‚úÖ gt_mask max: True, anomaly_map max: 3.030874013900757\n",
            "üîç Best threshold (F1-max): 2.1012\n",
            "üìä Confusion Matrix (Image-Level):\n",
            " [[61  9]\n",
            " [ 6 65]]\n",
            "‚úÖ F1 Score: 0.897 | Accuracy: 0.894\n",
            "üß© pred_masks unique values: [0 1]\n",
            "üìè Mean IoU (Defect Images Only): 0.2852\n",
            "Sample Auroc: 94.3, Pixel Auroc: 96.6, Pixel Aupro: 50.8\n",
            "MAX I_ROC: 95.5, MAX P_ROC: 96.7, MAX P_PRO: 52.4\n",
            "EarlyStopping counter: 1/3\n",
            "epoch [61/100], loss:18.6851\n",
            "epoch [62/100], loss:18.6879\n",
            "epoch [63/100], loss:18.6809\n",
            "epoch [64/100], loss:18.6894\n",
            "epoch [65/100], loss:18.6804\n",
            "epoch [66/100], loss:18.6737\n",
            "epoch [67/100], loss:18.6630\n",
            "epoch [68/100], loss:18.6619\n",
            "epoch [69/100], loss:18.6531\n",
            "epoch [70/100], loss:18.6441\n",
            "üïí FPS: 12.84\n",
            "‚úÖ gt_mask max: True, anomaly_map max: 2.9530930519104004\n",
            "üîç Best threshold (F1-max): 2.0679\n",
            "üìä Confusion Matrix (Image-Level):\n",
            " [[61  9]\n",
            " [ 8 63]]\n",
            "‚úÖ F1 Score: 0.881 | Accuracy: 0.879\n",
            "üß© pred_masks unique values: [0 1]\n",
            "üìè Mean IoU (Defect Images Only): 0.2865\n",
            "Sample Auroc: 93.5, Pixel Auroc: 96.6, Pixel Aupro: 50.0\n",
            "MAX I_ROC: 95.5, MAX P_ROC: 96.7, MAX P_PRO: 52.4\n",
            "EarlyStopping counter: 2/3\n",
            "epoch [71/100], loss:18.6463\n",
            "epoch [72/100], loss:18.6338\n",
            "epoch [73/100], loss:18.6337\n",
            "epoch [74/100], loss:18.6357\n",
            "epoch [75/100], loss:18.6314\n",
            "epoch [76/100], loss:18.6227\n",
            "epoch [77/100], loss:18.6159\n",
            "epoch [78/100], loss:18.6081\n",
            "epoch [79/100], loss:18.6041\n",
            "epoch [80/100], loss:18.6020\n",
            "üïí FPS: 12.90\n",
            "‚úÖ gt_mask max: True, anomaly_map max: 2.996985673904419\n",
            "üîç Best threshold (F1-max): 2.0056\n",
            "üìä Confusion Matrix (Image-Level):\n",
            " [[57 13]\n",
            " [ 7 64]]\n",
            "‚úÖ F1 Score: 0.865 | Accuracy: 0.858\n",
            "üß© pred_masks unique values: [0 1]\n",
            "üìè Mean IoU (Defect Images Only): 0.2727\n",
            "Sample Auroc: 92.1, Pixel Auroc: 96.2, Pixel Aupro: 49.7\n",
            "MAX I_ROC: 95.5, MAX P_ROC: 96.7, MAX P_PRO: 52.4\n",
            "EarlyStopping counter: 3/3\n",
            "Early stopping\n",
            "\n",
            "training over!\n",
            "testing on MVTec AD dataset (separate-class)\n",
            "testing class:wood\n",
            "cuda\n",
            "Loading weights from ./ckpts/MVTec AD/wood/BEST_P_PRO.pth\n",
            "üïí FPS: 13.04\n",
            "‚úÖ gt_mask max: True, anomaly_map max: 3.0279078483581543\n",
            "üîç Best threshold (F1-max): 2.1389\n",
            "üìä Confusion Matrix (Image-Level):\n",
            " [[59 11]\n",
            " [ 5 66]]\n",
            "‚úÖ F1 Score: 0.892 | Accuracy: 0.887\n",
            "üß© pred_masks unique values: [0 1]\n",
            "üìè Mean IoU (Defect Images Only): 0.2845\n",
            "\n",
            "| object   |   image_auroc |   pixel_auroc |   pixel_aupro |\n",
            "|:---------|--------------:|--------------:|--------------:|\n",
            "| wood     |          94.8 |          96.7 |          52.4 |\n",
            "| mean     |          94.8 |          96.7 |          52.4 |\n"
          ]
        }
      ],
      "source": [
        "!python '/content/UniNet/main.py' \\\n",
        "  --dataset \"MVTec AD\" \\\n",
        "  --setting oc \\\n",
        "  --train_and_test_all \\\n",
        "  --is_saved \\\n",
        "  --save_dir \"./results\" \\\n",
        "  --epoch 100\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def debug_predict(image_tensor, model, device):\n",
        "    image_tensor = image_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "\n",
        "        # üîç Model √ßƒ±ktƒ±sƒ±nƒ±n yapƒ±sƒ±nƒ± incele\n",
        "        if isinstance(output, tuple) and isinstance(output[0], list):\n",
        "            anomaly_map = output[0][0]\n",
        "        else:\n",
        "            raise ValueError(\"‚ö† Model √ßƒ±ktƒ±sƒ± tuple[list[tensor]] yapƒ±sƒ±nda deƒüil.\")\n",
        "\n",
        "        if not isinstance(anomaly_map, torch.Tensor):\n",
        "            raise TypeError(f\"‚ùå anomaly_map bir Tensor deƒüil: {type(anomaly_map)}\")\n",
        "\n",
        "        # üîç Anomaly map i≈üleme\n",
        "        anomaly_map = anomaly_map.mean(dim=1, keepdim=True)\n",
        "        anomaly_map = torch.nn.functional.interpolate(anomaly_map, size=(256, 256), mode=\"bilinear\", align_corners=False)\n",
        "        anomaly_map = anomaly_map.clamp(0, 1).cpu().squeeze().numpy()\n",
        "\n",
        "        # üîç Skor analizleri\n",
        "        raw_max = float(anomaly_map.max())\n",
        "        raw_mean = float(anomaly_map.mean())\n",
        "        raw_percentile = float(np.percentile(anomaly_map, 99))\n",
        "\n",
        "        # üîç DFS aƒüƒ±rlƒ±klarƒ± varsa kontrol et\n",
        "        if hasattr(model, 'dfs'):\n",
        "            try:\n",
        "                print(\"theta1 mean:\", model.dfs.theta1.mean().item())\n",
        "                print(\"theta2 mean:\", model.dfs.theta2.mean().item())\n",
        "                print(\"theta3 mean:\", model.dfs.theta3.mean().item())\n",
        "            except Exception as e:\n",
        "                print(\"(‚ö† DFS parametreleri okunamadƒ±)\", e)\n",
        "\n",
        "        print(f\"\\nüß† Skorlar:\\n - Max: {raw_max:.4f}\\n - Mean: {raw_mean:.4f}\\n - 99th %: {raw_percentile:.4f}\")\n",
        "\n",
        "        # üîç Karar\n",
        "        threshold = 0.15  # yeni d√º≈ü√ºk e≈üik\n",
        "        label = \"Anomali\" if raw_max > threshold else \"Normal\"\n",
        "        print(f\"üîé Tahmin: {label} (e≈üik: {threshold})\")\n",
        "\n",
        "        # üîç Haritayƒ± g√∂rselle≈ütir\n",
        "        plt.imshow(anomaly_map, cmap='jet')\n",
        "        plt.colorbar()\n",
        "        plt.title(f\"Anomaly Map\\nMax: {raw_max:.3f}, Mean: {raw_mean:.3f}, 99%: {raw_percentile:.3f}\\nLabel: {label}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return anomaly_map, raw_max, label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# BEST_P_PRO.pth dosyasƒ±nƒ±n yolunu belirt\n",
        "ckpt_path = \"/content/ckpts/MVTec AD/wood/BEST_P_PRO.pth\"  # Gerekirse tam yolu d√ºzelt\n",
        "\n",
        "checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "\n",
        "print(\"üì¶ Checkpoint tipi:\", type(checkpoint))\n",
        "\n",
        "# Eƒüer dict ise:\n",
        "if isinstance(checkpoint, dict):\n",
        "    print(\"üîë Anahtarlar:\", list(checkpoint.keys())[:10])\n",
        "\n",
        "    # Eƒüer doƒürudan dfs.weight gibi ≈üeyler varsa\n",
        "    if all(isinstance(v, torch.Tensor) for v in checkpoint.values()):\n",
        "        print(\"‚úÖ Doƒürudan state_dict (tek d√ºzeyli)\")\n",
        "        dfs_weights = {k: v.shape for k, v in checkpoint.items() if 'dfs' in k.lower()}\n",
        "        print(\"üîç DFS Aƒüƒ±rlƒ±klarƒ±:\", dfs_weights)\n",
        "\n",
        "    # Eƒüer alt mod√ºller varsa (dict i√ßinde dict)\n",
        "    elif all(isinstance(v, dict) for v in checkpoint.values()):\n",
        "        print(\"‚úÖ dict i√ßinde dict (mod√ºl bazlƒ± kaydedilmi≈ü)\")\n",
        "        for module_name in checkpoint.keys():\n",
        "            print(f\"üìÇ {module_name}: {list(checkpoint[module_name].keys())[:5]}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Beklenmeyen format:\", type(checkpoint))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwGsBcbIbHuX",
        "outputId": "2e34eb9f-3454-4805-f88c-5ec0816829d4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Checkpoint tipi: <class 'dict'>\n",
            "üîë Anahtarlar: ['tt', 'bn', 'st', 'dfs']\n",
            "‚úÖ dict i√ßinde dict (mod√ºl bazlƒ± kaydedilmi≈ü)\n",
            "üìÇ tt: ['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var']\n",
            "üìÇ bn: ['bn_layer.0.0.bn2.weight', 'bn_layer.0.0.bn2.bias', 'bn_layer.0.0.bn2.running_mean', 'bn_layer.0.0.bn2.running_var', 'bn_layer.0.0.bn2.num_batches_tracked']\n",
            "üìÇ st: ['layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var']\n",
            "üìÇ dfs: ['theta1', 'theta2', 'theta3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMpXY1w5_f5I",
        "outputId": "ade9e1b4-e798-4b87-8bf8-0753f85d3672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception ignored in: <function _get_module_lock.<locals>.cb at 0x78d192913240>\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 207, in cb\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UniNet/main.py\", line 4, in <module>\n",
            "    from train_unsupervisedAD import train\n",
            "  File \"/content/UniNet/train_unsupervisedAD.py\", line 10, in <module>\n",
            "    from datasets import loading_dataset\n",
            "  File \"/content/UniNet/datasets.py\", line 1, in <module>\n",
            "    from torchvision import transforms\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/ops/roi_align.py\", line 7, in <module>\n",
            "    from torch._dynamo.utils import is_compile_supported\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n",
            "    from . import convert_frame, eval_frame, resume_execution\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 33, in <module>\n",
            "    from torch._dynamo.symbolic_convert import TensorifyState\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 27, in <module>\n",
            "    from torch._dynamo.exc import TensorifyScalarRestartAnalysis\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\", line 11, in <module>\n",
            "    from .utils import counters\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\", line 66, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 74, in <module>\n",
            "    from torch.utils._sympy.functions import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_sympy/functions.py\", line 18, in <module>\n",
            "    import sympy\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/__init__.py\", line 74, in <module>\n",
            "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/polys/__init__.py\", line 79, in <module>\n",
            "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
            "    from sympy.polys.specialpolys import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
            "    from sympy.polys.rings import ring\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/polys/rings.py\", line 30, in <module>\n",
            "    from sympy.printing.defaults import DefaultPrinting\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/printing/__init__.py\", line 11, in <module>\n",
            "    from .pycode import pycode\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/printing/pycode.py\", line 11, in <module>\n",
            "    from .codeprinter import CodePrinter\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/printing/codeprinter.py\", line 13, in <module>\n",
            "    from sympy.functions.elementary.complexes import re\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/functions/__init__.py\", line 49, in <module>\n",
            "    from sympy.functions.special.beta_functions import beta, betainc, betainc_regularized\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/functions/special/beta_functions.py\", line 173, in <module>\n",
            "    class betainc(Function):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/core/basic.py\", line 182, in __init_subclass__\n",
            "    def __init_subclass__(cls):\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python '/content/UniNet/main.py' --dataset \"MVTec AD\" --setting oc --save_dir \"./results\" --load_ckpts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GlTRZgCBK5hC"
      },
      "outputs": [],
      "source": [
        "def test(c, suffix='BEST_P_PRO'):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"üñ•Ô∏è  Device: {device}\")\n",
        "\n",
        "    dataset_name = c.dataset\n",
        "\n",
        "    # üîÅ SENƒ∞N DOƒûRUDAN VERDƒ∞ƒûƒ∞N CHECKPOINT PATH\n",
        "    ckpt_path = \"/content/UniNet/ckpts/ckpts/MVTec AD/wood\"  # ‚Üê burada BEST_P_PRO.pth var\n",
        "\n",
        "    # Dataset y√ºkle\n",
        "    dataset_info = loading_dataset(c, dataset_name)\n",
        "    test_dataloader = dataset_info[1]\n",
        "\n",
        "    # Model tanƒ±mƒ± ve aƒüƒ±rlƒ±k y√ºkleme\n",
        "    Source_teacher, bn = wide_resnet50_2(c, pretrained=True)\n",
        "    Source_teacher.layer4 = None\n",
        "    Source_teacher.fc = None\n",
        "    student = de_wide_resnet50_2(pretrained=False)\n",
        "    DFS = DomainRelated_Feature_Selection()\n",
        "    [Source_teacher, bn, student, DFS] = to_device([Source_teacher, bn, student, DFS], device)\n",
        "    Target_teacher = copy.deepcopy(Source_teacher)\n",
        "\n",
        "    new_state = load_weights([Target_teacher, bn, student, DFS], ckpt_path, suffix)\n",
        "    Target_teacher = new_state['tt']\n",
        "    bn = new_state['bn']\n",
        "    student = new_state['st']\n",
        "    DFS = new_state['dfs']\n",
        "\n",
        "    model = UniNet(c, Source_teacher.cuda().eval(), Target_teacher, bn, student, DFS)\n",
        "\n",
        "    # Performans metriƒüi hesapla\n",
        "    auroc_px, auroc_sp, pro = evaluation_indusAD(c, model, test_dataloader, device)\n",
        "\n",
        "    return auroc_sp, auroc_px, pro, model, device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dqp6GPY4N_2a"
      },
      "outputs": [],
      "source": [
        "def test_all_images(c, model, device):\n",
        "    import glob\n",
        "    import os\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import cv2\n",
        "    import datetime\n",
        "    from torchvision import transforms as T\n",
        "    from scipy.ndimage import gaussian_filter\n",
        "    import torch\n",
        "    from torch.nn import functional as F\n",
        "\n",
        "    test_images_dir = f\"/content/UniNet/data/mvtec/{c._class_}/test/defect/\"\n",
        "    gt_dir = f\"/content/UniNet/data/mvtec/{c._class_}/ground_truth/defect/\"\n",
        "\n",
        "    image_paths = sorted(glob.glob(os.path.join(test_images_dir, \"*.jpg\")))\n",
        "    os.makedirs(\"all_results\", exist_ok=True)\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        filename = os.path.basename(img_path)\n",
        "        gt_path = os.path.join(gt_dir, filename.replace(\".jpg\", \"_mask.jpg\"))\n",
        "\n",
        "        original_image = Image.open(img_path).convert('RGB')\n",
        "        transform = T.Compose([\n",
        "            T.Resize((c.image_size, c.image_size)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        input_tensor = transform(original_image).unsqueeze(0).to(device)\n",
        "\n",
        "        model.train_or_eval(type='eval')\n",
        "        n = model.n\n",
        "        output_list = [list() for _ in range(n * 3)]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            t_tf, de_features = model(input_tensor)\n",
        "            for l, (t, s) in enumerate(zip(t_tf, de_features)):\n",
        "                output = 1 - F.cosine_similarity(t, s)\n",
        "                output_list[l].append(output)\n",
        "\n",
        "            anomaly_score, anomaly_map = weighted_decision_mechanism(1, output_list, c.alpha, c.beta)\n",
        "            anomaly_map = gaussian_filter(anomaly_map, sigma=4)\n",
        "            anomaly_map = anomaly_map.squeeze()\n",
        "\n",
        "        # Normalize heatmap\n",
        "        anomaly_map_norm = cv2.normalize(anomaly_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(anomaly_map_norm, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Contours\n",
        "        _, thresh = cv2.threshold(anomaly_map_norm, 127, 255, cv2.THRESH_BINARY)\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        original_cv = np.array(original_image.resize((c.image_size, c.image_size)))\n",
        "        original_cv = cv2.cvtColor(original_cv, cv2.COLOR_RGB2BGR)\n",
        "        contour_image = cv2.drawContours(original_cv.copy(), contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "        # GT mask\n",
        "        if os.path.exists(gt_path):\n",
        "            gt_mask = Image.open(gt_path).convert('L').resize((c.image_size, c.image_size))\n",
        "        else:\n",
        "            gt_mask = np.zeros_like(anomaly_map_norm)\n",
        "\n",
        "        # G√∂rseli Kaydet\n",
        "        label = \"defect\" if \"defect\" in img_path.lower() else \"good\"\n",
        "        img_number = filename.replace(\".jpg\", \"\")\n",
        "        save_path = f\"all_result/result_{label}_{img_number}.png\"\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        plt.subplot(1, 4, 1); plt.title(\"Original\"); plt.imshow(original_image.resize((c.image_size, c.image_size))); plt.axis('off')\n",
        "        plt.subplot(1, 4, 2); plt.title(\"Anomaly Map\"); plt.imshow(anomaly_map, cmap='jet'); plt.axis('off')\n",
        "        plt.subplot(1, 4, 3); plt.title(\"Contours\"); plt.imshow(cv2.cvtColor(contour_image, cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
        "        plt.subplot(1, 4, 4); plt.title(\"Ground Truth\"); plt.imshow(gt_mask, cmap='gray'); plt.axis('off')\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"[‚úì] {filename} -> Max Score: {anomaly_map.max().item():.4f}, saved to {save_path}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmke1u7MPXDm"
      },
      "outputs": [],
      "source": [
        "def test_all_images_gd(c, model, device):\n",
        "    import glob\n",
        "    import os\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import cv2\n",
        "    import datetime\n",
        "    from torchvision import transforms as T\n",
        "    from scipy.ndimage import gaussian_filter\n",
        "    import torch\n",
        "    from torch.nn import functional as F\n",
        "\n",
        "    test_images_dir = f\"/content/UniNet/data/mvtec/{c._class_}/test/*/\"\n",
        "    gt_dir = f\"/content/UniNet/data/mvtec/{c._class_}/ground_truth/\"\n",
        "\n",
        "    image_paths = sorted(glob.glob(os.path.join(test_images_dir, \"*.jpg\")))\n",
        "    os.makedirs(\"all_results\", exist_ok=True)\n",
        "\n",
        "    print(f\"Toplam {len(image_paths)} test g√∂r√ºnt√ºs√º bulundu.\")\n",
        "\n",
        "    # 1Ô∏è‚É£ T√ºm anomaly map max skorlarƒ±nƒ± topla\n",
        "    max_scores = []\n",
        "    anomaly_maps = []\n",
        "    processed = []\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        filename = os.path.basename(img_path)\n",
        "\n",
        "        original_image = Image.open(img_path).convert('RGB')\n",
        "        transform = T.Compose([\n",
        "            T.Resize((c.image_size, c.image_size)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        input_tensor = transform(original_image).unsqueeze(0).to(device)\n",
        "\n",
        "        model.train_or_eval(type='eval')\n",
        "        n = model.n\n",
        "        output_list = [list() for _ in range(n * 3)]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            t_tf, de_features = model(input_tensor)\n",
        "            for l, (t, s) in enumerate(zip(t_tf, de_features)):\n",
        "                output = 1 - F.cosine_similarity(t, s)\n",
        "                output_list[l].append(output)\n",
        "\n",
        "            anomaly_score, anomaly_map = weighted_decision_mechanism(1, output_list, c.alpha, c.beta)\n",
        "            anomaly_map = gaussian_filter(anomaly_map, sigma=4)\n",
        "            anomaly_map = anomaly_map.squeeze()\n",
        "\n",
        "        max_score = anomaly_map.max().item()\n",
        "        label = \"defect\" if max_score >= 1.98 else \"good\"\n",
        "\n",
        "        max_scores.append(max_score)\n",
        "        anomaly_maps.append(anomaly_map)\n",
        "        processed.append((img_path, original_image, anomaly_map, label, max_score))\n",
        "\n",
        "    global_max = max(max_scores)\n",
        "    print(f\"\\nüå°Ô∏è Global max anomaly score: {global_max:.4f}\\n\")\n",
        "\n",
        "    # 2Ô∏è‚É£ Normalize edip g√∂rselleri kaydet\n",
        "    for idx, (img_path, original_image, anomaly_map, label, max_score) in enumerate(processed):\n",
        "        filename = os.path.basename(img_path)\n",
        "        gt_path = os.path.join(gt_dir, label, filename.replace(\".jpg\", \"_mask.jpg\"))\n",
        "\n",
        "        anomaly_map_norm = (anomaly_map / global_max * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(anomaly_map_norm, cv2.COLORMAP_JET)\n",
        "\n",
        "        _, thresh = cv2.threshold(anomaly_map_norm, 127, 255, cv2.THRESH_BINARY)\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        original_cv = np.array(original_image.resize((c.image_size, c.image_size)))\n",
        "        original_cv = cv2.cvtColor(original_cv, cv2.COLOR_RGB2BGR)\n",
        "        contour_image = cv2.drawContours(original_cv.copy(), contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "        # GT mask\n",
        "        if os.path.exists(gt_path):\n",
        "            gt_mask = Image.open(gt_path).convert('L').resize((c.image_size, c.image_size))\n",
        "        else:\n",
        "            gt_mask = np.zeros_like(anomaly_map_norm)\n",
        "\n",
        "        save_path = f\"all_results/result_{label}_{filename.replace('.jpg', '')}.png\"\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        plt.subplot(1, 4, 1); plt.title(\"Original\"); plt.imshow(original_image.resize((c.image_size, c.image_size))); plt.axis('off')\n",
        "        plt.subplot(1, 4, 2); plt.title(\"Anomaly Map\"); plt.imshow(anomaly_map, cmap='jet'); plt.axis('off')\n",
        "        plt.subplot(1, 4, 3); plt.title(\"Contours\"); plt.imshow(cv2.cvtColor(contour_image, cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
        "        plt.subplot(1, 4, 4); plt.title(\"Ground Truth\"); plt.imshow(gt_mask, cmap='gray'); plt.axis('off')\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"[{idx+1}/{len(processed)}] ‚úì {filename} ‚Üí Max Score: {max_score:.4f}, Predicted: {label}, Saved to: {save_path}\")\n",
        "\n",
        "auroc_sp, auroc_px, pro, model, device = test(c)\n",
        "test_all_images_gd(c, model, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9vSYedTVXTe"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/UniNet/all_results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}