{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvyhueqP-Azu",
        "outputId": "a28e2801-0952-45d6-cc5d-0ad07d63be05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/donaldrr/simplenet.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JbEm1Nl__rl",
        "outputId": "79ec5629-6af4-4787-b3b9-c785a2d9fcf6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'simplenet'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 95 (delta 42), reused 31 (delta 31), pack-reused 39 (from 1)\u001b[K\n",
            "Receiving objects: 100% (95/95), 235.91 KiB | 21.45 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision scikit-learn opencv-python matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJyksNOdANN0",
        "outputId": "808e1816-bb9c-4368-ef20-d724b2f4126c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "metrics.py dosyasındaki .append() satırını otomatik olarak concat() ile değiştirildi"
      ],
      "metadata": {
        "id": "4TMJItcTF3x9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yeniden Adlandırma ve Dönüştürme Kodu"
      ],
      "metadata": {
        "id": "-uIcrRCCMQjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "gt_dir = \"/content/drive/MyDrive/wood_dataset/wood/ground_truth/defect\"\n",
        "updated = 0\n",
        "\n",
        "for fname in os.listdir(gt_dir):\n",
        "    if fname.endswith(\"_mask.jpg\"):\n",
        "        base_name = fname.replace(\"_mask.jpg\", \"\")\n",
        "        old_path = os.path.join(gt_dir, fname)\n",
        "        new_path = os.path.join(gt_dir, base_name + \".png\")\n",
        "\n",
        "        # JPG'yi PNG'ye dönüştür ve adlandır\n",
        "        img = Image.open(old_path).convert(\"L\")\n",
        "        img.save(new_path, format=\"PNG\")\n",
        "        updated += 1\n",
        "\n",
        "print(f\"{updated} dosya yeniden adlandırıldı ve PNG'ye dönüştürüldü ✅\")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT8elqxzMQ9n",
        "outputId": "0b851e84-1e7d-467c-c532-e7ce431167d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 dosya yeniden adlandırıldı ve PNG'ye dönüştürüldü ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import os\n",
        "\n",
        "gt_dir = \"/content/drive/MyDrive/wood_dataset/wood/ground_truth/defect\"\n",
        "deleted = 0\n",
        "\n",
        "for f in os.listdir(gt_dir):\n",
        "    if f.endswith(\"_mask.jpg\"):\n",
        "        os.remove(os.path.join(gt_dir, f))\n",
        "        deleted += 1\n",
        "\n",
        "print(f\"{deleted} adet '_mask.jpg' uzantılı eski maske silindi ✅\")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyMIWmoINnG6",
        "outputId": "f8b9a7f5-5545-4800-a571-051809eacebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 adet '_mask.jpg' uzantılı eski maske silindi ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "simplenet.py ve metrics.py f1 ve iou yazdırılması için güncellendi."
      ],
      "metadata": {
        "id": "ZbcEaB6zYwa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/simplenet/main.py \\\n",
        "--gpu 0 \\\n",
        "--seed 0 \\\n",
        "--log_group simplenet_wood_fast \\\n",
        "--log_project WoodOnly \\\n",
        "--results_path results \\\n",
        "--run_name wood_fast_run \\\n",
        "net \\\n",
        "-b wideresnet50 \\\n",
        "-le layer2 \\\n",
        "-le layer3 \\\n",
        "--pretrain_embed_dimension 1024 \\\n",
        "--target_embed_dimension 1024 \\\n",
        "--patchsize 3 \\\n",
        "--meta_epochs 15 \\\n",
        "--embedding_size 256 \\\n",
        "--gan_epochs 5 \\\n",
        "--noise_std 0.015 \\\n",
        "--dsc_hidden 768 \\\n",
        "--dsc_layers 2 \\\n",
        "--dsc_margin .5 \\\n",
        "--pre_proj 2 \\\n",
        "dataset \\\n",
        "--batch_size 8 \\\n",
        "--resize 256 \\\n",
        "--imagesize 256 \\\n",
        "-d wood \\\n",
        "mvtec /content/drive/MyDrive/wood_dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8RSJdjPDFJE",
        "outputId": "862bb3b0-3bbd-4275-96d8-e8e4535f7b83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-17 17:53:13.859205: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-17 17:53:13.876491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747504393.898651    5281 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747504393.905281    5281 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-17 17:53:13.926917: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO:__main__:Command line arguments: /content/simplenet/main.py --gpu 0 --seed 0 --log_group simplenet_wood_fast --log_project WoodOnly --results_path results --run_name wood_fast_run net -b wideresnet50 -le layer2 -le layer3 --pretrain_embed_dimension 1024 --target_embed_dimension 1024 --patchsize 3 --meta_epochs 15 --embedding_size 256 --gan_epochs 5 --noise_std 0.015 --dsc_hidden 768 --dsc_layers 2 --dsc_margin .5 --pre_proj 2 dataset --batch_size 8 --resize 256 --imagesize 256 -d wood mvtec /content/drive/MyDrive/wood_dataset\n",
            "INFO:__main__:Dataset: train=70 test=141\n",
            "INFO:__main__:Evaluating dataset [mvtec_wood] (1/1)...\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n",
            "100% 132M/132M [00:00<00:00, 228MB/s]\n",
            "INFO:__main__:Training models (1/1)\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.85814 lr:0.0002 p_true:0.119 p_fake:0.149: 100% 5/5 [00:52<00:00, 10.55s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 0 I-AUROC:0.4988(MAX:0.4988)  P-AUROC0.3934(MAX:0.3934)  PRO-AUROC0.0808(MAX:0.0808)  F1:0.0281  IoU:0.0143 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.67531 lr:0.0002 p_true:0.279 p_fake:0.313: 100% 5/5 [00:26<00:00,  5.22s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 1 I-AUROC:0.4994(MAX:0.4994)  P-AUROC0.5827(MAX:0.5827)  PRO-AUROC0.2212(MAX:0.2212)  F1:0.0475  IoU:0.0243 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.39702 lr:0.0002 p_true:0.436 p_fake:0.474: 100% 5/5 [00:26<00:00,  5.27s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 2 I-AUROC:0.5586(MAX:0.5586)  P-AUROC0.7132(MAX:0.7132)  PRO-AUROC0.3279(MAX:0.3279)  F1:0.064  IoU:0.0331 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.18069 lr:0.0002 p_true:0.631 p_fake:0.676: 100% 5/5 [00:26<00:00,  5.23s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 3 I-AUROC:0.7354(MAX:0.7354)  P-AUROC0.8119(MAX:0.8119)  PRO-AUROC0.6277(MAX:0.6277)  F1:0.0932  IoU:0.0489 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.08471 lr:0.0002 p_true:0.794 p_fake:0.805: 100% 5/5 [00:26<00:00,  5.27s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 4 I-AUROC:0.7441(MAX:0.7441)  P-AUROC0.7341(MAX:0.7341)  PRO-AUROC0.4996(MAX:0.4996)  F1:0.0717  IoU:0.0372 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.03662 lr:0.0002 p_true:0.888 p_fake:0.901: 100% 5/5 [00:26<00:00,  5.30s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 5 I-AUROC:0.7185(MAX:0.7441)  P-AUROC0.7765(MAX:0.7341)  PRO-AUROC0.5061(MAX:0.4996)  F1:0.0908  IoU:0.0476 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.03325 lr:0.0002 p_true:0.916 p_fake:0.93: 100% 5/5 [00:26<00:00,  5.27s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 6 I-AUROC:0.7811(MAX:0.7811)  P-AUROC0.8404(MAX:0.8404)  PRO-AUROC0.528(MAX:0.528)  F1:0.0881  IoU:0.0461 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.01549 lr:0.0002 p_true:0.955 p_fake:0.956: 100% 5/5 [00:26<00:00,  5.27s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 7 I-AUROC:0.7362(MAX:0.7811)  P-AUROC0.8301(MAX:0.8404)  PRO-AUROC0.5897(MAX:0.528)  F1:0.0908  IoU:0.0475 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.01524 lr:0.0002 p_true:0.961 p_fake:0.963: 100% 5/5 [00:26<00:00,  5.28s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 8 I-AUROC:0.7505(MAX:0.7811)  P-AUROC0.8042(MAX:0.8404)  PRO-AUROC0.5319(MAX:0.528)  F1:0.091  IoU:0.0477 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.014 lr:0.0002 p_true:0.977 p_fake:0.978: 100% 5/5 [00:26<00:00,  5.26s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 9 I-AUROC:0.7748(MAX:0.7811)  P-AUROC0.804(MAX:0.8404)  PRO-AUROC0.523(MAX:0.528)  F1:0.0762  IoU:0.0396 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.00524 lr:0.0002 p_true:0.984 p_fake:0.989: 100% 5/5 [00:26<00:00,  5.27s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 10 I-AUROC:0.7453(MAX:0.7811)  P-AUROC0.8337(MAX:0.8404)  PRO-AUROC0.5466(MAX:0.528)  F1:0.0883  IoU:0.0462 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.00385 lr:0.0002 p_true:0.99 p_fake:0.986: 100% 5/5 [00:26<00:00,  5.29s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 11 I-AUROC:0.7744(MAX:0.7811)  P-AUROC0.8697(MAX:0.8404)  PRO-AUROC0.6454(MAX:0.528)  F1:0.1134  IoU:0.0601 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.01617 lr:0.0002 p_true:0.978 p_fake:0.984: 100% 5/5 [00:26<00:00,  5.30s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 12 I-AUROC:0.7688(MAX:0.7811)  P-AUROC0.7637(MAX:0.8404)  PRO-AUROC0.456(MAX:0.528)  F1:0.0618  IoU:0.0319 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.01146 lr:0.0002 p_true:0.972 p_fake:0.975: 100% 5/5 [00:26<00:00,  5.27s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 13 I-AUROC:0.736(MAX:0.7811)  P-AUROC0.8169(MAX:0.8404)  PRO-AUROC0.4641(MAX:0.528)  F1:0.0798  IoU:0.0416 -----\n",
            "INFO:simplenet:Training discriminator...\n",
            "epoch:4 loss:0.00977 lr:0.0002 p_true:0.979 p_fake:0.985: 100% 5/5 [00:26<00:00,  5.30s/it]\n",
            "/content/simplenet/metrics.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n",
            "----- 14 I-AUROC:0.7435(MAX:0.7811)  P-AUROC0.7676(MAX:0.8404)  PRO-AUROC0.4038(MAX:0.528)  F1:0.0649  IoU:0.0335 -----\n",
            "INFO:__main__:instance_auroc: 0.781\n",
            "INFO:__main__:full_pixel_auroc: 0.840\n",
            "INFO:__main__:anomaly_pixel_auroc: 0.528\n",
            "INFO:__main__:\n",
            "\n",
            "-----\n",
            "\n",
            "INFO:utils:instance_auroc: 0.781\n",
            "INFO:utils:full_pixel_auroc: 0.840\n",
            "INFO:utils:anomaly_pixel_auroc: 0.528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/simplenet/main.py \\\n",
        "--gpu 0 \\\n",
        "--seed 0 \\\n",
        "--log_group simplenet_wood_fast \\\n",
        "--log_project WoodOnly \\\n",
        "--results_path results \\\n",
        "--run_name wood_fast_run \\\n",
        "--test \\\n",
        "--save_segmentation_images \\\n",
        "net \\\n",
        "-b wideresnet50 \\\n",
        "-le layer2 \\\n",
        "-le layer3 \\\n",
        "--pretrain_embed_dimension 1536 \\\n",
        "--target_embed_dimension 1536 \\\n",
        "--patchsize 3 \\\n",
        "--embedding_size 256 \\\n",
        "--gan_epochs 5 \\\n",
        "--noise_std 0.015 \\\n",
        "--dsc_hidden 768 \\\n",
        "--dsc_layers 2 \\\n",
        "--dsc_margin .5 \\\n",
        "--pre_proj 2 \\\n",
        "dataset \\\n",
        "--batch_size 8 \\\n",
        "--resize 256 \\\n",
        "--imagesize 256 \\\n",
        "-d wood \\\n",
        "mvtec /content/drive/MyDrive/wood_dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yDt0VLk5_7s",
        "outputId": "a312d5e8-d0bc-4482-f025-eac340643682"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-17 19:58:45.855766: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-17 19:58:45.873784: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747511925.895647   38161 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747511925.902185   38161 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-17 19:58:45.923780: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO:__main__:Command line arguments: /content/simplenet/main.py --gpu 0 --seed 0 --log_group simplenet_wood_fast --log_project WoodOnly --results_path results --run_name wood_fast_run --test --save_segmentation_images net -b wideresnet50 -le layer2 -le layer3 --pretrain_embed_dimension 1536 --target_embed_dimension 1536 --patchsize 3 --embedding_size 256 --gan_epochs 5 --noise_std 0.015 --dsc_hidden 768 --dsc_layers 2 --dsc_margin .5 --pre_proj 2 dataset --batch_size 8 --resize 256 --imagesize 256 -d wood mvtec /content/drive/MyDrive/wood_dataset\n",
            "INFO:__main__:Dataset: train=70 test=141\n",
            "INFO:__main__:Evaluating dataset [mvtec_wood] (1/1)...\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "INFO:__main__:Training models (1/1)\n",
            "INFO:__main__:instance_auroc: 0.611\n",
            "INFO:__main__:full_pixel_auroc: 0.750\n",
            "INFO:__main__:anomaly_pixel_auroc: nan\n",
            "INFO:__main__:\n",
            "\n",
            "-----\n",
            "\n",
            "INFO:utils:instance_auroc: 0.611\n",
            "INFO:utils:full_pixel_auroc: 0.750\n",
            "/content/simplenet/utils.py:153: RuntimeWarning: Mean of empty slice\n",
            "  mean_metrics[result_key] = np.nanmean([x[i] for x in results])\n",
            "INFO:utils:anomaly_pixel_auroc: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# === Klasör yolları\n",
        "heatmap_dir = \"/content/saved_heatmaps\"\n",
        "test_defect_dir = \"/content/drive/MyDrive/wood_dataset/wood/test/defect\"\n",
        "test_good_dir = \"/content/drive/MyDrive/wood_dataset/wood/test/good\"\n",
        "output_dir = \"/content/eval_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Parametreler\n",
        "img_size = (256, 256)\n",
        "quantile_value = 0.95\n",
        "results = []\n",
        "\n",
        "def process_image(name_id, category):\n",
        "    if category == \"defect\":\n",
        "        heatmap_name = name_id[-3:]\n",
        "        heatmap_path = os.path.join(heatmap_dir, f\"heatmap_{heatmap_name}.png\")\n",
        "        img_path = os.path.join(test_defect_dir, f\"{name_id}.png\")\n",
        "        contour_color = (0, 255, 0)\n",
        "    else:\n",
        "        heatmap_name = name_id.zfill(3)\n",
        "        heatmap_path = os.path.join(heatmap_dir, f\"heatmap_{heatmap_name}.png\")\n",
        "        img_path = os.path.join(test_good_dir, f\"{name_id}.png\")\n",
        "        contour_color = (0, 0, 255)\n",
        "\n",
        "    if not os.path.exists(heatmap_path) or not os.path.exists(img_path):\n",
        "        print(f\"❌ Eksik dosya: {name_id} ({category})\")\n",
        "        return\n",
        "\n",
        "    heatmap = cv2.imread(heatmap_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = cv2.imread(img_path)\n",
        "    heatmap = cv2.resize(heatmap, img_size)\n",
        "    image = cv2.resize(image, img_size)\n",
        "\n",
        "    # Normalize + Gaussian Blur\n",
        "    heatmap_norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
        "    heatmap_blurred = cv2.GaussianBlur(heatmap_norm, (5, 5), sigmaX=0)\n",
        "\n",
        "    threshold = np.quantile(heatmap_blurred, quantile_value)\n",
        "    binary_mask = (heatmap_blurred >= threshold).astype(np.uint8) * 255\n",
        "\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    overlay = image.copy()\n",
        "    cv2.drawContours(overlay, contours, -1, contour_color, 2)\n",
        "\n",
        "    # Gelişmiş anomaly skorları\n",
        "    flat = heatmap_blurred.flatten()\n",
        "    anomaly_ratio = np.sum(flat > threshold) / flat.size\n",
        "    mean_intensity = flat.mean()\n",
        "    max_intensity = flat.max()\n",
        "    topk_mean = np.mean(np.sort(flat)[-int(0.01 * flat.size):])  # üst %1\n",
        "\n",
        "    out_path = os.path.join(output_dir, f\"{category}_{name_id}.png\")\n",
        "    cv2.imwrite(out_path, overlay)\n",
        "\n",
        "    results.append({\n",
        "        \"image_id\": name_id,\n",
        "        \"category\": category,\n",
        "        \"quantile\": quantile_value,\n",
        "        \"threshold\": round(threshold, 4),\n",
        "        \"anomaly_ratio\": round(anomaly_ratio, 6),\n",
        "        \"mean_intensity\": round(mean_intensity, 6),\n",
        "        \"max_intensity\": round(max_intensity, 6),\n",
        "        \"topk_mean\": round(topk_mean, 6)\n",
        "    })\n",
        "\n",
        "# === Defect görsellerini işle\n",
        "defect_files = sorted([f for f in os.listdir(test_defect_dir) if f.endswith(\".png\")])\n",
        "for fname in tqdm(defect_files, desc=\"Defect Processing\"):\n",
        "    name_id = fname.replace(\".png\", \"\")\n",
        "    process_image(name_id, \"defect\")\n",
        "\n",
        "# === Good görsellerini işle\n",
        "good_files = sorted([f for f in os.listdir(test_good_dir) if f.endswith(\".png\")])\n",
        "for fname in tqdm(good_files, desc=\"Good Processing\"):\n",
        "    name_id = fname.replace(\".png\", \"\")\n",
        "    process_image(name_id, \"good\")\n",
        "\n",
        "# === Verileri DataFrame'e aktar\n",
        "df = pd.DataFrame(results)\n",
        "csv_path = os.path.join(output_dir, \"combined_anomaly_scores.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(f\"✅ Tüm anomaly skorları kaydedildi: {csv_path}\")\n",
        "\n",
        "# === Ground-truth etiketle\n",
        "df[\"true_label\"] = df[\"category\"].apply(lambda x: 1 if x == \"defect\" else 0)\n",
        "\n",
        "# === Özellikleri belirle\n",
        "X = df[[\"anomaly_ratio\", \"mean_intensity\", \"max_intensity\", \"topk_mean\"]].values\n",
        "y = df[\"true_label\"].values\n",
        "\n",
        "# === Decision Tree sınıflandırıcı\n",
        "clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# === Tahmin ve F1 skoru\n",
        "df[\"predicted_label\"] = clf.predict(X)\n",
        "f1 = f1_score(y, df[\"predicted_label\"])\n",
        "print(f\"🌳 Decision Tree ile F1 Score: {f1:.4f}\")\n",
        "\n",
        "# === Sonuçları kaydet\n",
        "csv_path = os.path.join(output_dir, \"combined_anomaly_scores_with_tree.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(f\"📄 Decision Tree sonuçları kaydedildi: {csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YykKjN112F2m",
        "outputId": "ec8e09ae-43c0-4f10-ab28-66196096dc40"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Defect Processing: 100%|██████████| 71/71 [00:05<00:00, 12.91it/s]\n",
            "Good Processing: 100%|██████████| 70/70 [00:08<00:00,  8.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tüm anomaly skorları kaydedildi: /content/eval_outputs/combined_anomaly_scores.csv\n",
            "🌳 Decision Tree ile F1 Score: 0.7204\n",
            "📄 Decision Tree sonuçları kaydedildi: /content/eval_outputs/combined_anomaly_scores_with_tree.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/eval_outputs"
      ],
      "metadata": {
        "id": "jB6wa5chFvu-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUEMLmQH-ALi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}