{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldPxCXXZzPnb",
        "outputId": "d55522d6-388d-4182-cccc-c2e23a18cdb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxHQsiYmym6B",
        "outputId": "d3cee509-8a03-4825-da21-2888562aac2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'INP-Former'...\n",
            "remote: Enumerating objects: 363, done.\u001b[K\n",
            "remote: Counting objects: 100% (363/363), done.\u001b[K\n",
            "remote: Compressing objects: 100% (304/304), done.\u001b[K\n",
            "remote: Total 363 (delta 105), reused 258 (delta 48), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (363/363), 6.53 MiB | 21.83 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/luow23/INP-Former.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy satırını atlatarak requirements dosyasını güncelle\n",
        "!grep -v \"numpy==1.19.0\" /content/INP-Former/requirements.txt > requirements_modified.txt\n",
        "!pip install -r requirements_modified.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MTOaexx1I-b",
        "outputId": "575c45be-8276-4c05-d641-979f376373a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting matplotlib==3.2.1 (from -r requirements_modified.txt (line 2))\n",
            "  Downloading matplotlib-3.2.1.tar.gz (40.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencv_python_headless==4.6.0.66 (from -r requirements_modified.txt (line 3))\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pandas==1.3.5 (from -r requirements_modified.txt (line 4))\n",
            "  Downloading pandas-1.3.5.tar.gz (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Pillow==9.0.1 (from -r requirements_modified.txt (line 5))\n",
            "  Downloading Pillow-9.0.1.tar.gz (49.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit_image==0.19.3 (from -r requirements_modified.txt (line 6))\n",
            "  Downloading scikit-image-0.19.3.tar.gz (22.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit_learn==0.22.2.post1 (from -r requirements_modified.txt (line 7))\n",
            "  Downloading scikit-learn-0.22.2.post1.tar.gz (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy==1.4.1 (from -r requirements_modified.txt (line 8))\n",
            "  Downloading scipy-1.4.1.tar.gz (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab uyumlu requirements (elle yazılmış modern sürümler)\n",
        "!pip install torch torchvision\n",
        "!pip install opencv-python-headless==4.7.0.72\n",
        "!pip install pandas==1.5.3\n",
        "!pip install Pillow==9.5.0\n",
        "!pip install scikit-image==0.19.3\n",
        "!pip install scikit-learn==1.1.3\n",
        "!pip install scipy==1.9.3\n",
        "!pip install matplotlib==3.5.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QFbruhLBD1hA",
        "outputId": "81dd6adf-a074-4385-f22a-e62d50836ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting opencv-python-headless==4.7.0.72\n",
            "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless==4.7.0.72) (2.0.2)\n",
            "Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 2.0.6 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed opencv-python-headless-4.7.0.72\n",
            "Collecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2025.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.17.0)\n",
            "Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m141.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.3 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.5.3\n",
            "Collecting Pillow==9.5.0\n",
            "  Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.5.0 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "a13cbf9b15ad404db0ceea24b83f5c8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-image==0.19.3\n",
            "  Using cached scikit-image-0.19.3.tar.gz (22.2 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (1.15.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (3.4.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (9.5.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (2025.3.30)\n",
            "Collecting PyWavelets>=1.1.1 (from scikit-image==0.19.3)\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (24.2)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: scikit-image\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n",
            "^C\n",
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy pandas\n",
        "!pip install numpy==1.24.3 pandas==1.5.3\n"
      ],
      "metadata": {
        "id": "VatO7YtvEzrr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "30f03b25-9cae-4da2-82ed-4209692d7d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: pandas 1.5.3\n",
            "Uninstalling pandas-1.5.3:\n",
            "  Successfully uninstalled pandas-1.5.3\n",
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting pandas==1.5.3\n",
            "  Using cached pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.17.0)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "Installing collected packages: numpy, pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.5.0 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.6 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.3 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3 pandas-1.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "59dae2121d1f4682aa658084616ae8ae"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kornia\n"
      ],
      "metadata": {
        "id": "JM3eJ13HE_zK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3134c1c-2cfc-4e4c-8e7e-3da4e27d59b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kornia\n",
            "  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting kornia_rs>=0.1.0 (from kornia)\n",
            "  Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kornia) (24.2)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from kornia) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.1->kornia) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.1->kornia) (3.0.2)\n",
            "Downloading kornia-0.8.0-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kornia_rs, kornia\n",
            "Successfully installed kornia-0.8.0 kornia_rs-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "def convert_to_png(directory):\n",
        "    image_paths = glob(os.path.join(directory, '*.jpg')) + glob(os.path.join(directory, '*.JPG'))\n",
        "    for img_path in image_paths:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        new_path = os.path.splitext(img_path)[0] + '.png'\n",
        "        img.save(new_path)\n",
        "        os.remove(img_path)  # orijinali sil\n",
        "\n",
        "# Ana yol\n",
        "base_path = \"/content/drive/MyDrive/wood_dataset/wood\"\n",
        "\n",
        "# İlgili alt dizinleri sırayla dön\n",
        "subfolders = [\n",
        "    \"train/good\",\n",
        "    \"test/good\",\n",
        "    \"test/defect\",\n",
        "    \"ground_truth/defect\"\n",
        "]\n",
        "\n",
        "for folder in subfolders:\n",
        "    convert_to_png(os.path.join(base_path, folder))\n",
        "\n",
        "print(\"✅ Tüm JPG dosyalar PNG formatına dönüştürüldü.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNA2cukWKGCt",
        "outputId": "4a2c98f9-8ace-4987-87ec-82bf807a9989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tüm JPG dosyalar PNG formatına dönüştürüldü.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mevcut problemli numpy ve pandas'ı kaldır\n",
        "!pip uninstall -y numpy pandas\n",
        "\n",
        "# Colab uyumlu pip kurulumu\n",
        "!pip install torch==2.0.1 torchvision==0.15.2\n",
        "!pip install matplotlib==3.5.3\n",
        "!pip install numpy==1.24.3 pandas==1.5.3\n",
        "!pip install opencv-python-headless==4.7.0.72\n",
        "!pip install Pillow==9.5.0\n",
        "!pip install scikit-image==0.19.3\n",
        "!pip install scikit-learn==1.1.3\n",
        "!pip install scipy==1.9.3\n",
        "!pip install tqdm==4.66.1\n",
        "!pip install tabulate==0.9.0\n",
        "!pip install timm==0.9.12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zmSkj7XpqCol",
        "outputId": "9b8e03c0-8ec9-478a-d3b7-e627571cf832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.2\n",
            "  Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting numpy (from torchvision==0.15.2)\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "db-dtypes 1.4.2 requires pandas>=0.24.2, which is not installed.\n",
            "arviz 0.21.0 requires pandas>=1.5.0, which is not installed.\n",
            "shap 0.47.2 requires pandas, which is not installed.\n",
            "dask-cuda 25.2.0 requires pandas>=1.3, which is not installed.\n",
            "statsmodels 0.14.4 requires pandas!=2.1.0,>=1.4, which is not installed.\n",
            "bqplot 0.12.44 requires pandas<3.0.0,>=1.0.0, which is not installed.\n",
            "xarray 2025.3.1 requires pandas>=2.1, which is not installed.\n",
            "mlxtend 0.23.4 requires pandas>=0.24.2, which is not installed.\n",
            "holoviews 1.20.2 requires pandas>=1.3, which is not installed.\n",
            "bokeh 3.7.2 requires pandas>=1.2, which is not installed.\n",
            "datascience 0.17.6 requires pandas, which is not installed.\n",
            "geemap 0.35.3 requires pandas, which is not installed.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, which is not installed.\n",
            "mizani 0.13.3 requires pandas>=2.2.0, which is not installed.\n",
            "bigframes 2.1.0 requires pandas>=1.5.3, which is not installed.\n",
            "pandas-gbq 0.28.0 requires pandas>=1.1.4, which is not installed.\n",
            "seaborn 0.13.2 requires pandas>=1.2, which is not installed.\n",
            "cmdstanpy 1.2.5 requires pandas, which is not installed.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, which is not installed.\n",
            "cufflinks 0.17.3 requires pandas>=0.19.2, which is not installed.\n",
            "prophet 1.1.6 requires pandas>=1.0.4, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires pandas, which is not installed.\n",
            "pymc 5.22.0 requires pandas>=0.24.0, which is not installed.\n",
            "yfinance 0.2.57 requires pandas>=1.3.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires pandas>=1.1.4, which is not installed.\n",
            "fastai 2.7.19 requires pandas, which is not installed.\n",
            "bigquery-magics 0.9.0 requires pandas>=1.1.0, which is not installed.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires pandas>=0.24.2, which is not installed.\n",
            "geopandas 1.0.1 requires pandas>=1.4.0, which is not installed.\n",
            "panel 1.6.3 requires pandas>=1.2, which is not installed.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 numpy-2.2.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchvision-0.15.2 triton-2.0.0\n",
            "Collecting matplotlib==3.5.3\n",
            "  Downloading matplotlib-3.5.3.tar.gz (35.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.5.3) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.3) (1.17.0)\n",
            "Building wheels for collected packages: matplotlib\n",
            "  Building wheel for matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for matplotlib: filename=matplotlib-3.5.3-cp311-cp311-linux_x86_64.whl size=11117186 sha256=bec28687e51b37d8e06c7ebf01b3ee42aa29f6f42d6a8a4ce139972bb1838c11\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/3b/87/b850f835f7a97bd28b0fb81fd73bdb17755122ea5ad71484f9\n",
            "Successfully built matplotlib\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.21.0 requires pandas>=1.5.0, which is not installed.\n",
            "mlxtend 0.23.4 requires pandas>=0.24.2, which is not installed.\n",
            "datascience 0.17.6 requires pandas, which is not installed.\n",
            "geemap 0.35.3 requires pandas, which is not installed.\n",
            "bigframes 2.1.0 requires pandas>=1.5.3, which is not installed.\n",
            "seaborn 0.13.2 requires pandas>=1.2, which is not installed.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, which is not installed.\n",
            "prophet 1.1.6 requires pandas>=1.0.4, which is not installed.\n",
            "pymc 5.22.0 requires pandas>=0.24.0, which is not installed.\n",
            "fastai 2.7.19 requires pandas, which is not installed.\n",
            "bigframes 2.1.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "4e139585a719436487d00f8a2ae0eb6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.17.0)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pandas\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.3 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "bigframes 2.1.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "blosc2 3.3.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3 pandas-1.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "6f95376e177e4cf6a22f3db7ac3ab8de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.7.0.72\n",
            "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless==4.7.0.72) (1.24.3)\n",
            "Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.6 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed opencv-python-headless-4.7.0.72\n",
            "Collecting Pillow==9.5.0\n",
            "  Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.5.0 which is incompatible.\n",
            "bigframes 2.1.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "e2a23c79f8b6482d860ee51f29ae2b26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-image==0.19.3\n",
            "  Downloading scikit-image-0.19.3.tar.gz (22.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hcanceled\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n",
            "^C\n",
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kornia\n",
        "!pip install adeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeN99-I2rObH",
        "outputId": "a95e66f5-d06b-4f27-909c-7ab5c900f224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kornia in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: kornia_rs>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from kornia) (0.1.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kornia) (24.2)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from kornia) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.1->kornia) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.1->kornia) (3.0.2)\n",
            "Collecting adeval\n",
            "  Downloading ADEval-1.1.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from adeval) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from adeval) (1.24.3)\n",
            "Requirement already satisfied: opencv-python>=3.4 in /usr/local/lib/python3.11/dist-packages (from adeval) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow>=4.0 in /usr/local/lib/python3.11/dist-packages (from adeval) (9.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->adeval) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->adeval) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->adeval) (3.0.2)\n",
            "Downloading ADEval-1.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: adeval\n",
            "Successfully installed adeval-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/INP-Former/INP_Former_Single_Class.py \\\n",
        "  --dataset MVTec-AD \\\n",
        "  --data_path /content/drive/MyDrive/wood_dataset \\\n",
        "  --item wood \\\n",
        "  --batch_size 4 \\\n",
        "  --total_epochs 50 \\\n",
        "  --phase train \\\n",
        "  --save_dir /content/inp_results \\\n",
        "  --encoder dinov2reg_vit_base_14 \\\n",
        "  --input_size 252 \\\n",
        "  --crop_size 252 \\\n",
        "  --INP_num 6\n"
      ],
      "metadata": {
        "id": "PF3HqqOr4cPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c5898c-2e97-4d9e-9950-598e7c1a0c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "INFO:dinov2:using MLP layer as FFN\n",
            "INFO:models.vit_encoder:Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_reg4_pretrain.pth\" to backbones/weights/dinov2_vitb14_reg4_pretrain.pth\n",
            "\n",
            "100% 330M/330M [00:01<00:00, 260MB/s]\n",
            "train image number: 70\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:train image number: 70\n",
            "100%|███████████████████████████████████████████| 17/17 [00:20<00:00,  1.18s/it]\n",
            "epoch [1/50], loss: 0.6993\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [1/50], loss: 0.6993\n",
            "100%|███████████████████████████████████████████| 17/17 [00:04<00:00,  3.93it/s]\n",
            "epoch [2/50], loss: 0.4041\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [2/50], loss: 0.4041\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.34it/s]\n",
            "epoch [3/50], loss: 0.3655\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [3/50], loss: 0.3655\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.26it/s]\n",
            "epoch [4/50], loss: 0.3621\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [4/50], loss: 0.3621\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.38it/s]\n",
            "epoch [5/50], loss: 0.3618\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [5/50], loss: 0.3618\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.34it/s]\n",
            "epoch [6/50], loss: 0.3524\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [6/50], loss: 0.3524\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.30it/s]\n",
            "epoch [7/50], loss: 0.3472\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [7/50], loss: 0.3472\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.27it/s]\n",
            "epoch [8/50], loss: 0.3416\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [8/50], loss: 0.3416\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.32it/s]\n",
            "epoch [9/50], loss: 0.3232\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [9/50], loss: 0.3232\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.36it/s]\n",
            "epoch [10/50], loss: 0.3248\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [10/50], loss: 0.3248\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.38it/s]\n",
            "epoch [11/50], loss: 0.3074\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [11/50], loss: 0.3074\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.33it/s]\n",
            "epoch [12/50], loss: 0.3161\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [12/50], loss: 0.3161\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.34it/s]\n",
            "epoch [13/50], loss: 0.3203\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [13/50], loss: 0.3203\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.28it/s]\n",
            "epoch [14/50], loss: 0.3488\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [14/50], loss: 0.3488\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.42it/s]\n",
            "epoch [15/50], loss: 0.3127\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [15/50], loss: 0.3127\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.37it/s]\n",
            "epoch [16/50], loss: 0.3066\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [16/50], loss: 0.3066\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.28it/s]\n",
            "epoch [17/50], loss: 0.2965\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [17/50], loss: 0.2965\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.36it/s]\n",
            "epoch [18/50], loss: 0.2890\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [18/50], loss: 0.2890\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.35it/s]\n",
            "epoch [19/50], loss: 0.2841\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [19/50], loss: 0.2841\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.33it/s]\n",
            "epoch [20/50], loss: 0.2820\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [20/50], loss: 0.2820\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.35it/s]\n",
            "epoch [21/50], loss: 0.2802\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [21/50], loss: 0.2802\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.39it/s]\n",
            "epoch [22/50], loss: 0.2721\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [22/50], loss: 0.2721\n",
            "100%|███████████████████████████████████████████| 17/17 [00:04<00:00,  4.22it/s]\n",
            "epoch [23/50], loss: 0.2681\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [23/50], loss: 0.2681\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.34it/s]\n",
            "epoch [24/50], loss: 0.2674\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [24/50], loss: 0.2674\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.41it/s]\n",
            "epoch [25/50], loss: 0.2695\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [25/50], loss: 0.2695\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.30it/s]\n",
            "epoch [26/50], loss: 0.2633\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [26/50], loss: 0.2633\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.34it/s]\n",
            "epoch [27/50], loss: 0.2610\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [27/50], loss: 0.2610\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.40it/s]\n",
            "epoch [28/50], loss: 0.2568\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [28/50], loss: 0.2568\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.31it/s]\n",
            "epoch [29/50], loss: 0.2544\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [29/50], loss: 0.2544\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.39it/s]\n",
            "epoch [30/50], loss: 0.2528\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [30/50], loss: 0.2528\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.30it/s]\n",
            "epoch [31/50], loss: 0.2511\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [31/50], loss: 0.2511\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.31it/s]\n",
            "epoch [32/50], loss: 0.2481\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [32/50], loss: 0.2481\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.41it/s]\n",
            "epoch [33/50], loss: 0.2467\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [33/50], loss: 0.2467\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.38it/s]\n",
            "epoch [34/50], loss: 0.2450\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [34/50], loss: 0.2450\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.35it/s]\n",
            "epoch [35/50], loss: 0.2439\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [35/50], loss: 0.2439\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.30it/s]\n",
            "epoch [36/50], loss: 0.2461\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [36/50], loss: 0.2461\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.33it/s]\n",
            "epoch [37/50], loss: 0.2432\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [37/50], loss: 0.2432\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.39it/s]\n",
            "epoch [38/50], loss: 0.2422\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [38/50], loss: 0.2422\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.28it/s]\n",
            "epoch [39/50], loss: 0.2412\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [39/50], loss: 0.2412\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.36it/s]\n",
            "epoch [40/50], loss: 0.2415\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [40/50], loss: 0.2415\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.31it/s]\n",
            "epoch [41/50], loss: 0.2405\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [41/50], loss: 0.2405\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.33it/s]\n",
            "epoch [42/50], loss: 0.2414\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [42/50], loss: 0.2414\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.41it/s]\n",
            "epoch [43/50], loss: 0.2394\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [43/50], loss: 0.2394\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.31it/s]\n",
            "epoch [44/50], loss: 0.2380\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [44/50], loss: 0.2380\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.32it/s]\n",
            "epoch [45/50], loss: 0.2380\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [45/50], loss: 0.2380\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.34it/s]\n",
            "epoch [46/50], loss: 0.2378\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [46/50], loss: 0.2378\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.35it/s]\n",
            "epoch [47/50], loss: 0.2378\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [47/50], loss: 0.2378\n",
            "100%|███████████████████████████████████████████| 17/17 [00:04<00:00,  4.24it/s]\n",
            "epoch [48/50], loss: 0.2373\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [48/50], loss: 0.2373\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.31it/s]\n",
            "epoch [49/50], loss: 0.2372\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [49/50], loss: 0.2372\n",
            "100%|███████████████████████████████████████████| 17/17 [00:03<00:00,  4.36it/s]\n",
            "epoch [50/50], loss: 0.2370\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:epoch [50/50], loss: 0.2370\n",
            "100%|███████████████████████████████████████████| 36/36 [00:45<00:00,  1.27s/it]\n",
            "wood: I-Auroc:0.8783, I-AP:0.8160, I-F1:0.8322, P-AUROC:0.9417, P-AP:0.2164, P-F1:0.3221, P-AUPRO:0.7574\n",
            "INFO:INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6:wood: I-Auroc:0.8783, I-AP:0.8160, I-F1:0.8322, P-AUROC:0.9417, P-AP:0.2164, P-F1:0.3221, P-AUPRO:0.7574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/INP-Former/INP_Former_Single_Class.py \\\n",
        "  --dataset MVTec-AD \\\n",
        "  --data_path /content/drive/MyDrive/wood_dataset \\\n",
        "  --item wood \\\n",
        "  --phase test \\\n",
        "  --save_dir /content/inp_results \\\n",
        "  --encoder dinov2reg_vit_base_14 \\\n",
        "  --input_size 252 \\\n",
        "  --crop_size 252 \\\n",
        "  --INP_num 6\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0B0KxeLQriC",
        "outputId": "b365df10-265a-43e6-c10d-030e3a6e20ad"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "INFO:dinov2:using MLP layer as FFN\n",
            "100%|███████████████████████████████████████████| 36/36 [00:05<00:00,  6.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from functools import partial\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score, jaccard_score\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "# === DİZİN AYARLARI ===\n",
        "test_dir = \"/content/drive/MyDrive/wood_dataset/wood/test/defect\"\n",
        "gt_dir = \"/content/drive/MyDrive/wood_dataset/wood/ground_truth/defect\"\n",
        "model_path = \"/content/inp_results/INP-Former-Single-Class_dataset=MVTec-AD_Encoder=dinov2reg_vit_base_14_Resize=252_Crop=252_INP_num=6/wood/model.pth\"\n",
        "output_vis_dir = \"/content/output_vis\"\n",
        "os.makedirs(output_vis_dir, exist_ok=True)\n",
        "\n",
        "# Farklı threshold değerlerini test etmek için\n",
        "threshold_test_dir = os.path.join(output_vis_dir, \"threshold_tests\")\n",
        "os.makedirs(threshold_test_dir, exist_ok=True)\n",
        "\n",
        "# === MODEL YÜKLE ===\n",
        "from models import vit_encoder\n",
        "from models.uad import INP_Former\n",
        "from models.vision_transformer import Mlp, Aggregation_Block, Prototype_Block\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "embed_dim = 768\n",
        "num_heads = 12\n",
        "INP_num = 6\n",
        "target_layers = [2, 3, 4, 5, 6, 7, 8, 9]\n",
        "fuse_layer_encoder = [[0, 1, 2, 3], [4, 5, 6, 7]]\n",
        "fuse_layer_decoder = [[0, 1, 2, 3], [4, 5, 6, 7]]\n",
        "\n",
        "encoder = vit_encoder.load('dinov2reg_vit_base_14')\n",
        "Bottleneck = nn.ModuleList([Mlp(embed_dim, embed_dim * 4, embed_dim, drop=0.)])\n",
        "INP = nn.ParameterList([nn.Parameter(torch.randn(INP_num, embed_dim))])\n",
        "INP_Extractor = nn.ModuleList([\n",
        "    Aggregation_Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=4., qkv_bias=True,\n",
        "                      norm_layer=partial(nn.LayerNorm, eps=1e-8))\n",
        "])\n",
        "INP_Guided_Decoder = nn.ModuleList([\n",
        "    Prototype_Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=4., qkv_bias=True,\n",
        "                    norm_layer=partial(nn.LayerNorm, eps=1e-8)) for _ in range(8)\n",
        "])\n",
        "\n",
        "model = INP_Former(\n",
        "    encoder=encoder,\n",
        "    bottleneck=Bottleneck,\n",
        "    aggregation=INP_Extractor,\n",
        "    decoder=INP_Guided_Decoder,\n",
        "    target_layers=target_layers,\n",
        "    remove_class_token=True,\n",
        "    fuse_layer_encoder=fuse_layer_encoder,\n",
        "    fuse_layer_decoder=fuse_layer_decoder,\n",
        "    prototype_token=INP\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# === DÖNÜŞÜMLER ===\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((252, 252)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Test edilecek threshold değerleri\n",
        "threshold_values = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "\n",
        "# Metrik sonuçları\n",
        "results_by_threshold = {thresh: {\"ious\": [], \"f1s\": []} for thresh in threshold_values}\n",
        "image_results = {}\n",
        "\n",
        "# === TÜM GÖRSELLERİ İŞLE ===\n",
        "for img_name in tqdm(sorted(os.listdir(test_dir))):\n",
        "    if not img_name.endswith(\".png\"): continue\n",
        "\n",
        "    img_path = os.path.join(test_dir, img_name)\n",
        "    gt_path = os.path.join(gt_dir, img_name)\n",
        "    if not os.path.exists(gt_path):\n",
        "        print(f\"⚠️ Ground truth yok: {gt_path}\")\n",
        "        continue\n",
        "\n",
        "    # Orijinal ve input tensor\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    orig_np = np.array(image.resize((252, 252)))\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Ground truth\n",
        "    gt = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
        "    gt = cv2.resize(gt, (252, 252))\n",
        "    gt_mask = (gt > 127).astype(np.uint8)\n",
        "\n",
        "    # === MODEL TAHMİNİ ===\n",
        "    with torch.no_grad():\n",
        "        # Modelin orijinal çıktılarını kullan\n",
        "        en_features, de_features, anomaly_map = model(input_tensor)\n",
        "\n",
        "        # Anomali haritasının şeklini ve içeriğini kontrol et\n",
        "        if isinstance(anomaly_map, torch.Tensor):\n",
        "            if len(anomaly_map.shape) == 4:  # B, C, H, W\n",
        "                # Kanal boyutu ortalama\n",
        "                anomaly_map = anomaly_map.mean(dim=1)\n",
        "            elif len(anomaly_map.shape) <= 2 or anomaly_map.numel() == 1:\n",
        "                # Tek değer veya 1D/2D tensor ise, yeniden yapılandır\n",
        "                # Encoder-Decoder çıktılarını kullanarak anomali haritası oluştur\n",
        "                anomaly_map = torch.norm(en_features[-1] - de_features[-1], dim=1)\n",
        "                anomaly_map = torch.nn.functional.interpolate(\n",
        "                    anomaly_map.unsqueeze(1),\n",
        "                    size=(252, 252),\n",
        "                    mode='bilinear',\n",
        "                    align_corners=False\n",
        "                ).squeeze(1)\n",
        "        else:\n",
        "            # Eğer anomaly_map tensor değilse, manuel olarak oluştur\n",
        "            anomaly_map = torch.norm(en_features[-1] - de_features[-1], dim=1)\n",
        "            anomaly_map = torch.nn.functional.interpolate(\n",
        "                anomaly_map.unsqueeze(1),\n",
        "                size=(252, 252),\n",
        "                mode='bilinear',\n",
        "                align_corners=False\n",
        "            ).squeeze(1)\n",
        "\n",
        "        # Tensor'dan numpy'a çevir\n",
        "        anomaly_map_np = anomaly_map.detach().cpu().numpy()\n",
        "\n",
        "    # Eğer batch boyutu varsa, ilk öğeyi al\n",
        "    if len(anomaly_map_np.shape) == 3 and anomaly_map_np.shape[0] == 1:\n",
        "        anomaly_map_np = anomaly_map_np[0]\n",
        "\n",
        "    # NaN veya inf değerleri kontrol et\n",
        "    if np.isnan(anomaly_map_np).any() or np.isinf(anomaly_map_np).any():\n",
        "        print(f\"⚠️ Anomali haritasında NaN veya inf değerler var: {img_name}\")\n",
        "        anomaly_map_np = np.nan_to_num(anomaly_map_np)\n",
        "\n",
        "    # Anomali haritasını 0-1 aralığına normalize et\n",
        "    min_val = np.min(anomaly_map_np)\n",
        "    max_val = np.max(anomaly_map_np)\n",
        "\n",
        "    if max_val - min_val < 1e-8:\n",
        "        print(f\"⚠️ Anomali haritası sabit değer içeriyor (min={min_val}, max={max_val})\")\n",
        "        anomaly_map_norm = np.zeros((252, 252), dtype=np.float32)\n",
        "    else:\n",
        "        anomaly_map_norm = (anomaly_map_np - min_val) / (max_val - min_val)\n",
        "\n",
        "    # Doğru boyuta getir\n",
        "    if anomaly_map_norm.shape != (252, 252):\n",
        "        anomaly_map_norm = cv2.resize(anomaly_map_norm.astype(np.float32), (252, 252), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Anomali haritasını düzeltmeler (gelişmiş işleme)\n",
        "    anomaly_map_smooth = cv2.GaussianBlur(anomaly_map_norm, (5, 5), 0)\n",
        "\n",
        "    # Bu görüntü için sonuçları sakla\n",
        "    image_results[img_name] = {\"best_iou\": 0, \"best_thresh\": 0, \"best_f1\": 0, \"results\": {}}\n",
        "\n",
        "    # Her bir threshold değerini dene\n",
        "    for thresh_val in threshold_values:\n",
        "        # Binary mask oluştur\n",
        "        pred_mask = (anomaly_map_smooth > thresh_val).astype(np.uint8)\n",
        "\n",
        "        # Morfolojik işlemler\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        pred_mask = cv2.morphologyEx(pred_mask, cv2.MORPH_OPEN, kernel)  # Küçük gürültüyü kaldır\n",
        "        pred_mask = cv2.morphologyEx(pred_mask, cv2.MORPH_CLOSE, kernel)  # Küçük delikleri kapat\n",
        "\n",
        "        # İlave morfolojik işlemler - isteğe bağlı\n",
        "        kernel_dilation = np.ones((2, 2), np.uint8)\n",
        "        pred_mask = cv2.dilate(pred_mask, kernel_dilation, iterations=1)\n",
        "\n",
        "        # Metrikler\n",
        "        try:\n",
        "            iou = jaccard_score(gt_mask.flatten(), pred_mask.flatten())\n",
        "            f1 = f1_score(gt_mask.flatten(), pred_mask.flatten())\n",
        "\n",
        "            # Sonuçları sakla\n",
        "            results_by_threshold[thresh_val][\"ious\"].append(iou)\n",
        "            results_by_threshold[thresh_val][\"f1s\"].append(f1)\n",
        "            image_results[img_name][\"results\"][thresh_val] = {\"iou\": iou, \"f1\": f1}\n",
        "\n",
        "            # En iyi sonucu güncelle\n",
        "            if iou > image_results[img_name][\"best_iou\"]:\n",
        "                image_results[img_name][\"best_iou\"] = iou\n",
        "                image_results[img_name][\"best_thresh\"] = thresh_val\n",
        "                image_results[img_name][\"best_f1\"] = f1\n",
        "\n",
        "            # Konturları çiz\n",
        "            overlay = orig_np.copy()\n",
        "            contours, _ = cv2.findContours(pred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 30]\n",
        "            cv2.drawContours(overlay, filtered_contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "            # Ground truth konturları\n",
        "            gt_contours, _ = cv2.findContours(gt_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cv2.drawContours(overlay, gt_contours, -1, (255, 0, 0), 1)\n",
        "\n",
        "            # Her threshold için görselleştir\n",
        "            fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "            axs[0].imshow(orig_np)\n",
        "            axs[0].set_title(\"Original\")\n",
        "            axs[1].imshow(overlay)\n",
        "            axs[1].set_title(f\"Threshold={thresh_val:.2f}, IoU={iou:.4f}, F1={f1:.4f}\")\n",
        "            axs[2].imshow(gt_mask, cmap=\"gray\")\n",
        "            axs[2].set_title(\"Ground Truth\")\n",
        "\n",
        "            for ax in axs:\n",
        "                ax.axis(\"off\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            save_path = os.path.join(threshold_test_dir, f\"{img_name.replace('.png','')}_thresh_{thresh_val:.2f}.jpg\")\n",
        "            plt.savefig(save_path, dpi=150)\n",
        "            plt.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Metrik hesaplama hatası: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Bu görüntü için en iyi threshold kullanılarak son görselleştirme\n",
        "    best_thresh = image_results[img_name][\"best_thresh\"]\n",
        "    best_iou = image_results[img_name][\"best_iou\"]\n",
        "    best_f1 = image_results[img_name][\"best_f1\"]\n",
        "\n",
        "    # En iyi threshold için maske oluştur\n",
        "    pred_mask = (anomaly_map_smooth > best_thresh).astype(np.uint8)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    pred_mask = cv2.morphologyEx(pred_mask, cv2.MORPH_OPEN, kernel)\n",
        "    pred_mask = cv2.morphologyEx(pred_mask, cv2.MORPH_CLOSE, kernel)\n",
        "    kernel_dilation = np.ones((2, 2), np.uint8)\n",
        "    pred_mask = cv2.dilate(pred_mask, kernel_dilation, iterations=1)\n",
        "\n",
        "    # Konturları çiz\n",
        "    overlay = orig_np.copy()\n",
        "    contours, _ = cv2.findContours(pred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 30]\n",
        "    cv2.drawContours(overlay, filtered_contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "    # Ground truth konturları\n",
        "    gt_contours, _ = cv2.findContours(gt_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(overlay, gt_contours, -1, (255, 0, 0), 1)\n",
        "\n",
        "    # En iyi sonucu görselleştir\n",
        "    fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
        "    axs[0].imshow(orig_np)\n",
        "    axs[0].set_title(\"Original\")\n",
        "    axs[1].imshow(anomaly_map_smooth, cmap='jet')\n",
        "    axs[1].set_title(f\"Anomaly Map (min={min_val:.2f}, max={max_val:.2f})\")\n",
        "    axs[2].imshow(overlay)\n",
        "    axs[2].set_title(f\"Best Thresh={best_thresh:.2f}, IoU={best_iou:.4f}, F1={best_f1:.4f}\")\n",
        "    axs[3].imshow(gt_mask, cmap=\"gray\")\n",
        "    axs[3].set_title(\"Ground Truth\")\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    best_save_path = os.path.join(output_vis_dir, f\"{img_name.replace('.png','')}_best.jpg\")\n",
        "    plt.savefig(best_save_path, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    # İlave olarak anomali haritası ve maske ayrı ayrı kaydedilsin\n",
        "    cv2.imwrite(os.path.join(output_vis_dir, f\"{img_name.replace('.png','')}_heatmap.png\"),\n",
        "                (anomaly_map_smooth * 255).astype(np.uint8))\n",
        "    cv2.imwrite(os.path.join(output_vis_dir, f\"{img_name.replace('.png','')}_mask.png\"),\n",
        "                pred_mask * 255)\n",
        "\n",
        "# === ORTALAMA METRİKLER ===\n",
        "print(\"\\n=== HER THRESHOLD DEĞERİ İÇİN SONUÇLAR ===\")\n",
        "best_avg_iou = 0\n",
        "best_thresh_overall = 0\n",
        "best_avg_f1 = 0\n",
        "\n",
        "for thresh in threshold_values:\n",
        "    avg_iou = np.mean(results_by_threshold[thresh][\"ious\"]) if results_by_threshold[thresh][\"ious\"] else 0\n",
        "    avg_f1 = np.mean(results_by_threshold[thresh][\"f1s\"]) if results_by_threshold[thresh][\"f1s\"] else 0\n",
        "    print(f\"Threshold={thresh:.2f}: IoU={avg_iou:.4f}, F1={avg_f1:.4f}\")\n",
        "\n",
        "    if avg_iou > best_avg_iou:\n",
        "        best_avg_iou = avg_iou\n",
        "        best_thresh_overall = thresh\n",
        "        best_avg_f1 = avg_f1\n",
        "\n",
        "print(f\"\\n=== EN İYİ GENEL THRESHOLD ===\")\n",
        "print(f\"Threshold={best_thresh_overall:.2f}: IoU={best_avg_iou:.4f}, F1={best_avg_f1:.4f}\")\n",
        "\n",
        "# Her görüntü için en iyi threshold değerlerinin dağılımı\n",
        "best_thresholds = [image_results[img][\"best_thresh\"] for img in image_results]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(best_thresholds, bins=threshold_values, alpha=0.7, color='blue')\n",
        "plt.title('En İyi Threshold Değerlerinin Dağılımı')\n",
        "plt.xlabel('Threshold Değeri')\n",
        "plt.ylabel('Görüntü Sayısı')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig(os.path.join(output_vis_dir, \"threshold_histogram.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Sonuçları bir metin dosyasına kaydet\n",
        "with open(os.path.join(output_vis_dir, \"threshold_results.txt\"), 'w') as f:\n",
        "    f.write(\"=== HER THRESHOLD DEĞERİ İÇİN ORTALAMA METRIKLER ===\\n\")\n",
        "    for thresh in threshold_values:\n",
        "        avg_iou = np.mean(results_by_threshold[thresh][\"ious\"]) if results_by_threshold[thresh][\"ious\"] else 0\n",
        "        avg_f1 = np.mean(results_by_threshold[thresh][\"f1s\"]) if results_by_threshold[thresh][\"f1s\"] else 0\n",
        "        f.write(f\"Threshold={thresh:.2f}: IoU={avg_iou:.4f}, F1={avg_f1:.4f}\\n\")\n",
        "\n",
        "    f.write(\"\\n=== EN İYİ GENEL THRESHOLD ===\\n\")\n",
        "    f.write(f\"Threshold={best_thresh_overall:.2f}: IoU={best_avg_iou:.4f}, F1={best_avg_f1:.4f}\\n\")\n",
        "\n",
        "    f.write(\"\\n=== GÖRÜNTÜ BAZLI SONUÇLAR ===\\n\")\n",
        "    for img_name in sorted(image_results.keys()):\n",
        "        best_thresh = image_results[img_name][\"best_thresh\"]\n",
        "        best_iou = image_results[img_name][\"best_iou\"]\n",
        "        best_f1 = image_results[img_name][\"best_f1\"]\n",
        "        f.write(f\"{img_name}: Best_Threshold={best_thresh:.2f}, IoU={best_iou:.4f}, F1={best_f1:.4f}\\n\")\n",
        "\n",
        "print(\"\\n✅ Tüm işlemler tamamlandı. Sonuçlar kaydedildi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xssIKAxBWhOQ",
        "outputId": "32efd0ae-e54d-4a31-8e5e-a23fbe7a28ca"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 71/71 [03:18<00:00,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== HER THRESHOLD DEĞERİ İÇİN SONUÇLAR ===\n",
            "Threshold=0.20: IoU=0.0284, F1=0.0543\n",
            "Threshold=0.30: IoU=0.0408, F1=0.0759\n",
            "Threshold=0.40: IoU=0.0696, F1=0.1233\n",
            "Threshold=0.50: IoU=0.1152, F1=0.1927\n",
            "Threshold=0.60: IoU=0.1518, F1=0.2463\n",
            "Threshold=0.70: IoU=0.1759, F1=0.2702\n",
            "Threshold=0.80: IoU=0.1346, F1=0.2107\n",
            "\n",
            "=== EN İYİ GENEL THRESHOLD ===\n",
            "Threshold=0.70: IoU=0.1759, F1=0.2702\n",
            "\n",
            "✅ Tüm işlemler tamamlandı. Sonuçlar kaydedildi.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0mlevivmYHxi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}